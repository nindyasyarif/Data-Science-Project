#Random Forest Regression
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

# Features (drop 'price' and other non-relevant columns like 'id', 'host_id')
X = df.drop(columns=['name', 'host_name', 'neighbourhood', 'id', 'host_id', 'price'])

# Target (predicting 'price')
y = df['price']

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# keep the 'last_review' but convert it, extract features like year and month
df['last_review_year'] = df['last_review'].dt.year
df['last_review_month'] = df['last_review'].dt.month

# drop the original 'last_review' column
X = df.drop(columns=['last_review', 'name', 'host_name', 'id', 'host_id', 'price'])

# Perform one-hot encoding on remaining categorical columns
X = pd.get_dummies(X, drop_first=True)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the RandomForestRegressor model
model = RandomForestRegressor(random_state=42)

# Train the model
model.fit(X_train, y_train)

from sklearn.metrics import mean_squared_error, r2_score

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate Mean Squared Error (MSE) and R-squared (R2)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared: {r2}")

#Gradient Boosting Regressor
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Impute missing values in the target variable (price) with the median
y_filled = y.fillna(y.median())
X_filled = X.fillna(X.median())

# Verify if any missing values remain
missing_values_after_imputation = X_filled.isnull().sum()
missing_values_after_imputation

# Split the data again to ensure the target variable is cleaned
X_train, X_test, y_train, y_test = train_test_split(X_filled, y_filled, test_size=0.2, random_state=42)

# Initialize the Gradient Boosting Regressor
gbr = GradientBoostingRegressor()
# Train the model
gbr.fit(X_train, y_train)

# Make predictions on the test set
y_pred_gbr = gbr.predict(X_test)

# Calculate Mean Squared Error (MSE) and R-squared (RÂ²)
mse_gbr = mean_squared_error(y_test, y_pred_gbr)
r2_gbr = r2_score(y_test, y_pred_gbr)

print(f"Gradient Boosting - Mean Squared Error: {mse_gbr}")
print(f"Gradient Boosting - R-squared: {r2_gbr}")
